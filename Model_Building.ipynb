{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Importing important Dependancies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***DataSet Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Churn_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Exploratory Data Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns (if needed)\n",
    "df = df.drop(['Unnamed: 0', 'state', 'area.code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change of coloumn Data Type object to int\n",
    "df['day.charge'] = pd.to_numeric(df['day.charge'], errors='coerce')\n",
    "df['eve.mins'] = pd.to_numeric(df['eve.mins'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "account.length      int64\n",
       "voice.plan         object\n",
       "voice.messages      int64\n",
       "intl.plan          object\n",
       "intl.mins         float64\n",
       "intl.calls          int64\n",
       "intl.charge       float64\n",
       "day.mins          float64\n",
       "day.calls           int64\n",
       "day.charge        float64\n",
       "eve.mins          float64\n",
       "eve.calls           int64\n",
       "eve.charge        float64\n",
       "night.mins        float64\n",
       "night.calls         int64\n",
       "night.charge      float64\n",
       "customer.calls      int64\n",
       "churn              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['account.length', 'voice.plan', 'voice.messages', 'intl.plan',\n",
       "       'intl.mins', 'intl.calls', 'intl.charge', 'day.mins', 'day.calls',\n",
       "       'day.charge', 'eve.mins', 'eve.calls', 'eve.charge', 'night.mins',\n",
       "       'night.calls', 'night.charge', 'customer.calls', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['voice.plan'] = label_encoder.fit_transform(df['voice.plan'])\n",
    "df['intl.plan'] = label_encoder.fit_transform(df['intl.plan'])\n",
    "df['churn'] = label_encoder.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Feature Selection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose a different strategy based on your data\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 86.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[850  11]\n",
      " [129  10]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       861\n",
      "           1       0.48      0.07      0.12       139\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.67      0.53      0.52      1000\n",
      "weighted avg       0.81      0.86      0.81      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression Classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logreg_classifier.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg_classifier.predict(X_test_imputed)\n",
    "\n",
    "# Evaluation\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of Logistic Regression: {accuracy*100}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.8\n",
      "\n",
      "Confusion Matrix:\n",
      " [[851  10]\n",
      " [ 32 107]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       861\n",
      "           1       0.91      0.77      0.84       139\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.94      0.88      0.91      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "model1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model1.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Support Vector Machine***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.5\n",
      "\n",
      "Confusion Matrix:\n",
      " [[861   0]\n",
      " [135   4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       861\n",
      "           1       1.00      0.03      0.06       139\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.93      0.51      0.49      1000\n",
      "weighted avg       0.88      0.86      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Initialize the SVM Classifier\n",
    "model = SVC()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Decision Tree Classifier Algorithm***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier: 93.30000000000001\n",
      "\n",
      "Confusion Matrix:\n",
      " [[829  32]\n",
      " [ 35 104]]\n",
      "Classification Report Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       861\n",
      "           1       0.76      0.75      0.76       139\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt_classifier.predict(X_test_imputed)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Decision Tree Classifier: {accuracy*100}\")\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print(\"Classification Report Decision Tree Classifier:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***K-Nearest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-Nearest Classifier: 89.3\n",
      "Classification Report of K-Nearest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       861\n",
      "           1       0.78      0.32      0.46       139\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.84      0.65      0.70      1000\n",
      "weighted avg       0.88      0.89      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_classifier.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_classifier.predict(X_test_imputed)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of K-Nearest Classifier: {accuracy*100}\")\n",
    "print(\"Classification Report of K-Nearest Classifier:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Naives Bayes Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naives Bayes Classifier: 63.7\n",
      "Classification Report Naives Bayes Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75       861\n",
      "           1       0.23      0.68      0.34       139\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.58      0.65      0.55      1000\n",
      "weighted avg       0.83      0.64      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Multinomial Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_classifier.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb_classifier.predict(X_test_imputed)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Naives Bayes Classifier: {accuracy*100}\")\n",
    "print(\"Classification Report Naives Bayes Classifier:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Gaussian Naive Bayes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes: 85.3\n",
      "Classification Report of Gaussian Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       861\n",
      "           1       0.48      0.56      0.51       139\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.70      0.73      0.71      1000\n",
      "weighted avg       0.86      0.85      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Gaussian Naive Bayes Classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "gnb_classifier.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = gnb_classifier.predict(X_test_imputed)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Gaussian Naive Bayes: {accuracy*100}\")\n",
    "print(\"Classification Report of Gaussian Naive Bayes:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Deep Learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "113/113 [==============================] - 3s 7ms/step - loss: 0.6442 - accuracy: 0.8611 - val_loss: 0.6273 - val_accuracy: 0.8300\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.8611 - val_loss: 0.5772 - val_accuracy: 0.8300\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8611 - val_loss: 0.5395 - val_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.8611 - val_loss: 0.5125 - val_accuracy: 0.8300\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8611 - val_loss: 0.4931 - val_accuracy: 0.8300\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.8611 - val_loss: 0.4794 - val_accuracy: 0.8300\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8611 - val_loss: 0.4702 - val_accuracy: 0.8300\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8611 - val_loss: 0.4640 - val_accuracy: 0.8300\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8611 - val_loss: 0.4601 - val_accuracy: 0.8300\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8611 - val_loss: 0.4578 - val_accuracy: 0.8300\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8611 - val_loss: 0.4565 - val_accuracy: 0.8300\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8611 - val_loss: 0.4560 - val_accuracy: 0.8300\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8611 - val_loss: 0.4559 - val_accuracy: 0.8300\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8611 - val_loss: 0.4561 - val_accuracy: 0.8300\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8611 - val_loss: 0.4565 - val_accuracy: 0.8300\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8611 - val_loss: 0.4570 - val_accuracy: 0.8300\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8611 - val_loss: 0.4574 - val_accuracy: 0.8300\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8611 - val_loss: 0.4578 - val_accuracy: 0.8300\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8611 - val_loss: 0.4581 - val_accuracy: 0.8300\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8611 - val_loss: 0.4584 - val_accuracy: 0.8300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8610\n",
      "Accuracy: 0.8610000014305115\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Accuracy of Sequential Model is: 86.1\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       861\n",
      "           1       0.00      0.00      0.00       139\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.43      0.50      0.46      1000\n",
      "weighted avg       0.74      0.86      0.80      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bhair\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assume X_train, X_test, y_train, and y_test are already loaded and imputed\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train_scaled.shape[1],), activation='sigmoid'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(y_train_encoded[0]), activation='softmax'))  # Adjust the number of output nodes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_encoded, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_encoded = model.predict(X_test_scaled)\n",
    "y_pred_classes = y_pred_encoded.argmax(axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original labels\n",
    "y_test_classes = y_test_encoded.argmax(axis=1)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "report = classification_report(y_test_classes, y_pred_classes)\n",
    "\n",
    "print(f\"Accuracy of Sequential Model is: {accuracy*100}\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model1,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
